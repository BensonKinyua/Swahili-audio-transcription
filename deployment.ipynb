{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create simple budget app\n",
    "\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "st.title('Simple Budget App')\n",
    "\n",
    "# Read in the data\n",
    "@st.cache\n",
    "def get_data():\n",
    "    df = pd.read_csv('https://raw.githubusercontent.com/justmarkham/DAT8/master/data/budget.csv')\n",
    "    return df\n",
    "\n",
    "df = get_data()\n",
    "\n",
    "# Create a text element and let the reader know that we are still working\n",
    "st.markdown(\"\"\"\n",
    "We are working on a simple budget app.\n",
    "\"\"\")\n",
    "\n",
    "# Add a title to the sidebar\n",
    "st.sidebar.title('Budget App')\n",
    "\n",
    "# Add a text element\n",
    "st.sidebar.markdown(\"\"\"\n",
    "This app is designed to help you track your expenses.\n",
    "\"\"\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# app.py\n",
    "import streamlit as st\n",
    "import joblib  # Import joblib to load the Pickle model\n",
    "import asyncio\n",
    "import threading\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Pickle model\n",
    "model = joblib.load('model_CNN.pkl')\n",
    "\n",
    "# Create input components (e.g., text input, sliders, etc.)\n",
    "user_input = st.text_input(\"Enter input:\", r\"spectrograms\\id_0a9r27bb48na.png\")\n",
    "translated_output = st.text_input(\"Enter text input:\", r\"spectrograms\\id_0a9r27bb48na.png\")\n",
    "\n",
    "data_df = pd.DataFrame({'user_input': [user_input], 'translated_output': [translated_output]})\n",
    "if st.button(\"Predict\"):\n",
    "    # Use the loaded model to make predictions\n",
    "    prediction = model.predict(data_df)\n",
    "    st.write(f\"Prediction: {prediction}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-16 22:32:38.362 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run c:\\Users\\admin\\Desktop\\project 5\\ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import joblib\n",
    "import asyncio\n",
    "import threading\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Pickle model\n",
    "model = joblib.load('model_CNN.pkl')\n",
    "\n",
    "# title\n",
    "st.title(\"ASR Model\")\n",
    "\n",
    "# Create input components (e.g., text input, sliders, etc.)\n",
    "user_input = st.audio(\"Enter audio input:\", \"\")\n",
    "translated_output = st.text_input(\"Enter text input:\", r\"spectrograms\\id_0a9r27bb48na.png\")\n",
    "\n",
    "# Function to run the prediction asynchronously\n",
    "async def predict_async(data_df):\n",
    "    # Your asynchronous prediction code here\n",
    "    prediction = model.predict(data_df)\n",
    "    st.write(f\"Prediction: {prediction}\")\n",
    "\n",
    "# Create a Streamlit button to trigger the async prediction\n",
    "if st.button(\"Predict\"):\n",
    "    data_df = pd.DataFrame({'user_input': [user_input], 'translated_output': [translated_output]})\n",
    "    asyncio.run(predict_async(data_df))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid __array_struct__",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\admin\\Desktop\\project 5\\deployment.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/admin/Desktop/project%205/deployment.ipynb#W2sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m translated_output\u001b[39m=\u001b[39m st\u001b[39m.\u001b[39mtext_input(\u001b[39m\"\u001b[39m\u001b[39mEnter text input:\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mspectrograms\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mid_0a9r27bb48na.png\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/admin/Desktop/project%205/deployment.ipynb#W2sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# create dataframe from data\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/admin/Desktop/project%205/deployment.ipynb#W2sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m data_df\u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mDataFrame({\u001b[39m'\u001b[39;49m\u001b[39muser_input\u001b[39;49m\u001b[39m'\u001b[39;49m: [user_input], \u001b[39m'\u001b[39;49m\u001b[39mtranslated_output\u001b[39;49m\u001b[39m'\u001b[39;49m: [translated_output]})\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/admin/Desktop/project%205/deployment.ipynb#W2sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mif\u001b[39;00m st\u001b[39m.\u001b[39mbutton(\u001b[39m\"\u001b[39m\u001b[39mPredict\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/admin/Desktop/project%205/deployment.ipynb#W2sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     \u001b[39m# Use the loaded model to make predictions\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/admin/Desktop/project%205/deployment.ipynb#W2sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     prediction \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(data_df)\n",
      "File \u001b[1;32mc:\\Users\\admin\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\frame.py:709\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    703\u001b[0m     mgr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_mgr(\n\u001b[0;32m    704\u001b[0m         data, axes\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m\"\u001b[39m: index, \u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m: columns}, dtype\u001b[39m=\u001b[39mdtype, copy\u001b[39m=\u001b[39mcopy\n\u001b[0;32m    705\u001b[0m     )\n\u001b[0;32m    707\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, \u001b[39mdict\u001b[39m):\n\u001b[0;32m    708\u001b[0m     \u001b[39m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 709\u001b[0m     mgr \u001b[39m=\u001b[39m dict_to_mgr(data, index, columns, dtype\u001b[39m=\u001b[39;49mdtype, copy\u001b[39m=\u001b[39;49mcopy, typ\u001b[39m=\u001b[39;49mmanager)\n\u001b[0;32m    710\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, ma\u001b[39m.\u001b[39mMaskedArray):\n\u001b[0;32m    711\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mnumpy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mma\u001b[39;00m \u001b[39mimport\u001b[39;00m mrecords\n",
      "File \u001b[1;32mc:\\Users\\admin\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\internals\\construction.py:481\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    477\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    478\u001b[0m         \u001b[39m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    479\u001b[0m         arrays \u001b[39m=\u001b[39m [x\u001b[39m.\u001b[39mcopy() \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(x, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39melse\u001b[39;00m x \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m arrays]\n\u001b[1;32m--> 481\u001b[0m \u001b[39mreturn\u001b[39;00m arrays_to_mgr(arrays, columns, index, dtype\u001b[39m=\u001b[39;49mdtype, typ\u001b[39m=\u001b[39;49mtyp, consolidate\u001b[39m=\u001b[39;49mcopy)\n",
      "File \u001b[1;32mc:\\Users\\admin\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\internals\\construction.py:120\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    117\u001b[0m         index \u001b[39m=\u001b[39m ensure_index(index)\n\u001b[0;32m    119\u001b[0m     \u001b[39m# don't force copy because getting jammed in an ndarray anyway\u001b[39;00m\n\u001b[1;32m--> 120\u001b[0m     arrays, refs \u001b[39m=\u001b[39m _homogenize(arrays, index, dtype)\n\u001b[0;32m    121\u001b[0m     \u001b[39m# _homogenize ensures\u001b[39;00m\n\u001b[0;32m    122\u001b[0m     \u001b[39m#  - all(len(x) == len(index) for x in arrays)\u001b[39;00m\n\u001b[0;32m    123\u001b[0m     \u001b[39m#  - all(x.ndim == 1 for x in arrays)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    126\u001b[0m \n\u001b[0;32m    127\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    128\u001b[0m     index \u001b[39m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32mc:\\Users\\admin\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\internals\\construction.py:607\u001b[0m, in \u001b[0;36m_homogenize\u001b[1;34m(data, index, dtype)\u001b[0m\n\u001b[0;32m    604\u001b[0m         val \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(val)\n\u001b[0;32m    605\u001b[0m     val \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39mfast_multiget(val, oindex\u001b[39m.\u001b[39m_values, default\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mnan)\n\u001b[1;32m--> 607\u001b[0m val \u001b[39m=\u001b[39m sanitize_array(val, index, dtype\u001b[39m=\u001b[39;49mdtype, copy\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    608\u001b[0m com\u001b[39m.\u001b[39mrequire_length_match(val, index)\n\u001b[0;32m    609\u001b[0m refs\u001b[39m.\u001b[39mappend(\u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\admin\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\construction.py:602\u001b[0m, in \u001b[0;36msanitize_array\u001b[1;34m(data, index, dtype, copy, allow_2d)\u001b[0m\n\u001b[0;32m    599\u001b[0m     subarr \u001b[39m=\u001b[39m _try_cast(data, dtype, copy)\n\u001b[0;32m    601\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 602\u001b[0m     subarr \u001b[39m=\u001b[39m maybe_convert_platform(data)\n\u001b[0;32m    603\u001b[0m     \u001b[39mif\u001b[39;00m subarr\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m \u001b[39mobject\u001b[39m:\n\u001b[0;32m    604\u001b[0m         subarr \u001b[39m=\u001b[39m cast(np\u001b[39m.\u001b[39mndarray, subarr)\n",
      "File \u001b[1;32mc:\\Users\\admin\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py:128\u001b[0m, in \u001b[0;36mmaybe_convert_platform\u001b[1;34m(values)\u001b[0m\n\u001b[0;32m    125\u001b[0m arr: ArrayLike\n\u001b[0;32m    127\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(values, (\u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m, \u001b[39mrange\u001b[39m)):\n\u001b[1;32m--> 128\u001b[0m     arr \u001b[39m=\u001b[39m construct_1d_object_array_from_listlike(values)\n\u001b[0;32m    129\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    130\u001b[0m     \u001b[39m# The caller is responsible for ensuring that we have np.ndarray\u001b[39;00m\n\u001b[0;32m    131\u001b[0m     \u001b[39m#  or ExtensionArray here.\u001b[39;00m\n\u001b[0;32m    132\u001b[0m     arr \u001b[39m=\u001b[39m values\n",
      "File \u001b[1;32mc:\\Users\\admin\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py:1542\u001b[0m, in \u001b[0;36mconstruct_1d_object_array_from_listlike\u001b[1;34m(values)\u001b[0m\n\u001b[0;32m   1539\u001b[0m \u001b[39m# numpy will try to interpret nested lists as further dimensions, hence\u001b[39;00m\n\u001b[0;32m   1540\u001b[0m \u001b[39m# making a 1D array that contains list-likes is a bit tricky:\u001b[39;00m\n\u001b[0;32m   1541\u001b[0m result \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty(\u001b[39mlen\u001b[39m(values), dtype\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mobject\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 1542\u001b[0m result[:] \u001b[39m=\u001b[39m values\n\u001b[0;32m   1543\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "\u001b[1;31mValueError\u001b[0m: invalid __array_struct__"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import joblib  # Import joblib to load the Pickle model\n",
    "import asyncio\n",
    "import threading\n",
    "import pandas as pd\n",
    "# Load the Pickle model\n",
    "model = joblib.load('model_CNN.pkl')\n",
    "\n",
    "# title\n",
    "st.title(\"ASR Model\")\n",
    "\n",
    "# Create input components (e.g., text input, sliders, etc.)\n",
    "user_input = st.audio(\"Enter audio input:\", \"\")\n",
    "translated_output= st.text_input(\"Enter text input:\", r\"spectrograms\\id_0a9r27bb48na.png\")\n",
    "\n",
    "# create dataframe from data\n",
    "data_df= pd.DataFrame({'user_input': [user_input], 'translated_output': [translated_output]})\n",
    "if st.button(\"Predict\"):\n",
    "    # Use the loaded model to make predictions\n",
    "    prediction = model.predict(data_df)\n",
    "    st.write(f\"Prediction: {prediction}\")\n",
    "\n",
    "# Your asyncio function\n",
    "async def my_async_function():\n",
    "    # Your asynchronous code here\n",
    "\n",
    "# Function to run asyncio in a separate thread\n",
    "    def run_async_function():\n",
    "\n",
    "        loop = asyncio.new_event_loop()\n",
    "        asyncio.set_event_loop(loop)\n",
    "        loop.run_until_complete(my_async_function())\n",
    "        asyncio.run(my_async_function())\n",
    "        loop.run_until_complete(my_async_function())\n",
    "\n",
    "# Create a Streamlit button to trigger the async function\n",
    "if st.button(\"Run Async Code\"):\n",
    "    thread = threading.Thread(target=run_async_function)\n",
    "    thread.start()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "demo = gr.Interface(\n",
    "    fn=recommend_hotels_restaurants,\n",
    "    inputs=[\"text\", gr.Slider(0, 5)],\n",
    "    outputs=[\"list\"],\n",
    ")\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-16 13:53:30.950 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run c:\\Users\\admin\\anaconda3\\envs\\learn-env\\lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import joblib  # Import joblib to load the Pickle model\n",
    "import librosa\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Load the Pickle model\n",
    "model = joblib.load('model_CNN.pkl')\n",
    "\n",
    "# Create input components for audio and spectrogram\n",
    "audio_file = st.file_uploader(r'Swahili_words\\id_0a9r27bb48na.wav', type=[\"wav\"])\n",
    "spectrogram_image = st.file_uploader(r\"Swahili_Classification_Project/spectrograms/id_0a9r27bb48na.png\", type=[\"png\", \"jpg\", \"jpeg\"])\n",
    "\n",
    "if audio_file is not None and spectrogram_image is not None:\n",
    "    # Read the uploaded audio file\n",
    "    audio_data, _ = librosa.load(audio_file, sr=None)  # Load audio data\n",
    "\n",
    "    # Read the spectrogram image\n",
    "    spectrogram_img = Image.open(spectrogram_image)\n",
    "\n",
    "    if st.button(\"Predict\"):\n",
    "        # Preprocess the audio data (you may need to adjust this based on your model's requirements)\n",
    "        # For example, you may need to reshape, normalize, and possibly convert to spectrogram\n",
    "        preprocessed_audio = r'Swahili_words\\id_0a9r27bb48na.wav' #preprocess_audio(audio_data)  # Implement preprocess_audio\n",
    "\n",
    "        # Preprocess the spectrogram image (resize, convert to array, etc.)\n",
    "        preprocessed_spectrogram = r'Swahili_Classification_Project\\spectrograms\\id_0a9r27bb48na.png' #preprocess_spectrogram(spectrogram_img)  # Implement preprocess_spectrogram\n",
    "\n",
    "        # Use the loaded model to make predictions\n",
    "        prediction = model.predict([preprocessed_audio, preprocessed_spectrogram])[0]\n",
    "        st.write(f\"Prediction: {prediction}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ResNet' object has no attribute 'save'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mUntitled-1.ipynb Cell 3\u001b[0m line \u001b[0;36m9\n\u001b[0;32m      <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#W3sdW50aXRsZWQ%3D?line=5'>6</a>\u001b[0m model \u001b[39m=\u001b[39m joblib\u001b[39m.\u001b[39mload(\u001b[39m'\u001b[39m\u001b[39mmodel_CNN.pkl\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#W3sdW50aXRsZWQ%3D?line=7'>8</a>\u001b[0m \u001b[39m# save as h5 file\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#W3sdW50aXRsZWQ%3D?line=8'>9</a>\u001b[0m model\u001b[39m.\u001b[39;49msave(\u001b[39m'\u001b[39m\u001b[39mmodel_CNN.h5\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#W3sdW50aXRsZWQ%3D?line=10'>11</a>\u001b[0m \u001b[39m# Load the CNN model for audio classification\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#W3sdW50aXRsZWQ%3D?line=11'>12</a>\u001b[0m model \u001b[39m=\u001b[39m load_model(\u001b[39m'\u001b[39m\u001b[39mmodel_CNN.h5\u001b[39m\u001b[39m'\u001b[39m)  \u001b[39m# Assuming it's a Keras model saved as an h5 file\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\admin\\anaconda3\\envs\\learn-env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1614\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1612\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m modules:\n\u001b[0;32m   1613\u001b[0m         \u001b[39mreturn\u001b[39;00m modules[name]\n\u001b[1;32m-> 1614\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m   1615\u001b[0m     \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, name))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'ResNet' object has no attribute 'save'"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import joblib  # Import joblib to load the Pickle model\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model  # Import the model loading function\n",
    "\n",
    "model = joblib.load('model_CNN.pkl')\n",
    "\n",
    "# save as h5 file\n",
    "model.save('model_CNN.h5')\n",
    "\n",
    "# Load the CNN model for audio classification\n",
    "model = load_model('model_CNN.h5')  # Assuming it's a Keras model saved as an h5 file\n",
    "\n",
    "# Create an input component to upload audio files\n",
    "audio_file = st.file_uploader(\"Upload an audio file\", type=[\"wav\"])\n",
    "\n",
    "if audio_file is not None:\n",
    "    # Read the uploaded audio file\n",
    "    audio_data = np.frombuffer(audio_file.read(), np.int16)  # Assuming 16-bit WAV audio\n",
    "\n",
    "    if st.button(\"Predict\"):\n",
    "        # Preprocess the audio data (you may need to adjust this based on your model's requirements)\n",
    "        # For example, you may need to reshape, normalize, and possibly convert to spectrogram\n",
    "        preprocessed_audio = preprocess_audio(audio_data)  # Implement preprocess_audio\n",
    "\n",
    "        # Use the loaded model to make predictions\n",
    "        prediction = model.predict(np.expand_dims(preprocessed_audio, axis=0))\n",
    "\n",
    "        # Display the prediction\n",
    "        st.write(f\"Prediction: {prediction}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StreamlitModel:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def predict(self, data):\n",
    "        data = np.expand_dims(data, axis=0)\n",
    "        prediction = self.model.predict(data)\n",
    "        return prediction\n",
    "    \n",
    "\n",
    "# Create an input component to upload audio files\n",
    "audio_file = st.file_uploader(\"Upload an audio file\", type=[\"wav\"])\n",
    "\n",
    "if audio_file is not None:\n",
    "    # Read the uploaded audio file\n",
    "    audio_data = np.frombuffer(audio_file.read(), np.int16)  # Assuming 16-bit WAV audio\n",
    "\n",
    "    if st.button(\"Predict\"):\n",
    "        # Preprocess the audio data (you may need to adjust this based on your model's requirements)\n",
    "        # For example, you may need to reshape, normalize, and possibly convert to spectrogram\n",
    "        preprocessed_audio = preprocess_audio(audio_data)  # Implement preprocess_audio\n",
    "\n",
    "        # Use the loaded model to make predictions\n",
    "        prediction = model.predict(np.expand_dims(preprocessed_audio, axis=0))\n",
    "\n",
    "        # Display the prediction\n",
    "        st.write(f\"Prediction: {prediction}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
